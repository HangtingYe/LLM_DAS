You are an expert in anomaly detection systems. The training set contains only normal samples. We use a PCA detector, where the anomaly score is computed using model.predict_score(). The higher the score, the more anomalous the sample.

# The description of PCA.
Principal Component Analysis (PCA) is a commonly used method for dimensionality reduction and anomaly detection. It identifies directions in the data (called principal components) along which the variance is maximized. In anomaly detection, PCA can be used to reconstruct each sample from the top principal components and compute the reconstruction error as the anomaly score. Samples with higher reconstruction error are considered more anomalous.

The main steps of PCA for anomaly detection are:

* Compute the mean of the training data.

* Subtract the mean from each sample to center the data.

* Compute the covariance matrix of the centered data.

* Perform eigen-decomposition on the covariance matrix to obtain eigenvectors and eigenvalues.

* Select the top eigenvectors corresponding to the largest eigenvalues to serve as the principal components.

* Project each sample onto the principal components and reconstruct it.

* Compute the reconstruction error for each sample as the anomaly score.

* Rank samples by their anomaly scores to detect anomalies.

# Objective
Your task is to write a Python function generate_hard_anomalies(...) that generates anomalies which are the most difficult for the PCA detector to detect. This means that the generated anomalies should have relatively low anomaly score, thus they are hard to be detected. But these anomalies are helpful to build a more robust detector. After the Python function is completed, users can provide the function with:

* A trained PCA model (model) that exposes predict_score(),

* The training samples (X_train)

# Requirements:
Your should strictly follow below requirements:

1. You must use your expertise to give anomalies generation policies that are specifically designed for PCA, not a model-agnostic policy.

2. Generated samples should have as low a score as possible from model.predict_score(). To achieve it, you can first find the set of borderline normal training samples based on your unique and professional understanding of PCA, not only based on the anomaly score. Then transform them to anomalies that are tailor-designed for PCA. Please note that the transformation should be specific to PCA, not a general transformation for other detectors.

3. For the model, you can only use the function model.predict_score.

4. Use NumPy to generate the samples, and output an array of shape (n_samples, d). It should generate as many anomalies as requested.

5. The function should allow setting:
   * the number of samples (n_samples),
   * the trained PCA model (model),
   * training samples (X_train).

   Thus the function format is generate_hard_anomalies(n_samples: int, model, X_train: np.ndarray)

6. All package imports must be done inside the function.

Return only the complete Python function generate_hard_anomalies(...), with the policy used for generating anomalies and clear comments explaining key steps.

